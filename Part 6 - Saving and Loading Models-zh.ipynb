{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存和加载模型\n",
    "\n",
    "在这个 notebook 中，我将为你展示如何使用 Pytorch 来保存和加载模型。这个步骤十分重要，因为你一定希望能够加载预先训练好的模型来进行预测，或是根据新数据继续训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, ), (0.5, ))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们可以看见一张图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 389,
       "width": 389
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_4_0.png)\n",
    "\n",
    "\n",
    "## 构建网络\n",
    "\n",
    "在这里，我将使用与第五部分中一样的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "    (1): Linear(in_features=500, out_features=100, bias=True)\n",
       "  )\n",
       "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(784,10, [500, 100])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练网络\n",
    "\n",
    "并使用之前一样的方法来训练网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "model = Network(784, 10, [500, 100])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.087..  Test Loss: 0.652..  Test Accuracy: 0.757\n",
      "Epoch: 1/2..  Training Loss: 0.733..  Test Loss: 0.580..  Test Accuracy: 0.790\n",
      "Epoch: 1/2..  Training Loss: 0.658..  Test Loss: 0.527..  Test Accuracy: 0.806\n",
      "Epoch: 1/2..  Training Loss: 0.606..  Test Loss: 0.509..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.590..  Test Loss: 0.503..  Test Accuracy: 0.811\n",
      "Epoch: 1/2..  Training Loss: 0.598..  Test Loss: 0.510..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.563..  Test Loss: 0.477..  Test Accuracy: 0.820\n",
      "Epoch: 1/2..  Training Loss: 0.544..  Test Loss: 0.468..  Test Accuracy: 0.824\n",
      "Epoch: 1/2..  Training Loss: 0.547..  Test Loss: 0.468..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.512..  Test Loss: 0.457..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.527..  Test Loss: 0.469..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.464..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.527..  Test Loss: 0.449..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.498..  Test Loss: 0.440..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.485..  Test Loss: 0.439..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.499..  Test Loss: 0.442..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.494..  Test Loss: 0.434..  Test Accuracy: 0.842\n",
      "Epoch: 2/2..  Training Loss: 0.481..  Test Loss: 0.431..  Test Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 100\n",
    "\n",
    "for e in range(epochs):\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        # 将图像扁平化为784长度的向量\n",
    "        images = images.view(images.size()[0], 784)\n",
    "        \n",
    "        # 将图像和标签包装在变量中，以便计算梯度\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # 模型评估模式，禁用dropout\n",
    "            model.eval()\n",
    "            \n",
    "            accuracy = 0\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():  # 禁用梯度计算\n",
    "                for ii, (images, labels) in enumerate(testloader):\n",
    "                    images = images.view(images.size()[0], 784)\n",
    "                    inputs = Variable(images)\n",
    "                    labels = Variable(labels)\n",
    "\n",
    "                    output = model.forward(inputs)\n",
    "                    test_loss += criterion(output, labels).item()\n",
    "                    \n",
    "                    # 计算准确率\n",
    "                    ps = torch.exp(output).data\n",
    "                    equality = (labels.data == ps.max(1)[1])\n",
    "                    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "            \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            # 确保训练时启用dropout\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和加载模型\n",
    "\n",
    "可以想象，在每次使用神经网络时都重新进行训练很不现实。因此，我们可以保存之前训练好的网络，并在继续训练或是进行预测时加载网络。\n",
    "\n",
    "PyTorch 网络的参数都存储在模型的 `state_dict` 中。我们可以看到这个状态字典包含了每个层的权重和偏差矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): Linear(in_features=500, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network: \n",
    "\n",
    " Network(\n",
    "  (hidden_layers): ModuleList(\n",
    "    (0): Linear(in_features=784, out_features=500)\n",
    "    (1): Linear(in_features=500, out_features=100)\n",
    "  )\n",
    "  (output): Linear(in_features=100, out_features=10)\n",
    ") \n",
    "\n",
    "The state dict keys: \n",
    "\n",
    " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最简单的做法是使用 `torch.save` 来保存状态字典。比如，我们可以将它保存到文件 `'checkpoint.pth'` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们可以使用 `torch.load` 来加载这个状态字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要将状态字典加载到神经网络中，你需要使用 `model.load_state_dict(state_dict)'`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这看上去十分简单，但实际情况更加复杂。只有当模型结构与检查点的结构完全一致时，状态字典才能成功加载。如果我在创建模型时使用了不同的结构，便无法顺利加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try this\n",
    "# net = Network(784, 10, [400, 200, 100])\n",
    "# # This will throw an error because the tensor sizes are wrong!\n",
    "# net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "\n",
    "~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict)\n",
    "    481                 try:\n",
    "--> 482                     own_state[name].copy_(param)\n",
    "    483                 except Exception:\n",
    "\n",
    "\n",
    "RuntimeError: inconsistent tensor size, expected tensor [400 x 784] and src [500 x 784] to have the same number of elements, but got 313600 and 392000 elements respectively at /Users/soumith/minicondabuild3/conda-bld/pytorch_1512381214802/work/torch/lib/TH/generic/THTensorCopy.c:86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "\n",
    "<ipython-input-18-74e14cc8e983> in <module>()\n",
    "      2 net = Network(784, 10, [400, 200, 100])\n",
    "      3 # This will throw an error because the tensor sizes are wrong!\n",
    "----> 4 net.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict)\n",
    "    485                                        'whose dimensions in the model are {} and '\n",
    "    486                                        'whose dimensions in the checkpoint are {}.'\n",
    "--> 487                                        .format(name, own_state[name].size(), param.size()))\n",
    "    488             elif strict:\n",
    "    489                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
    "\n",
    "\n",
    "RuntimeError: While copying the parameter named hidden_layers.0.weight, whose dimensions in the model are torch.Size([400, 784]) and whose dimensions in the checkpoint are torch.Size([500, 784]).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这意味着我们需要重建一个与训练时完全相同的模型。有关模型结构的信息需要与状态字典一起存储在检查点中。为了做到这一点，你需要构建一个字典，字典中包含重建模型的全部信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，检查点中包含了重建训练模型所需的全部信息。你可以随意将它编写为函数。相似地，我们也可以编写一个函数来加载检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network(checkpoint['input_size'],\n",
    "                    checkpoint['output_size'],\n",
    "                    checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): Linear(in_features=500, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Network(\n",
    "  (hidden_layers): ModuleList(\n",
    "    (0): Linear(in_features=784, out_features=500)\n",
    "    (1): Linear(in_features=500, out_features=100)\n",
    "  )\n",
    "  (output): Linear(in_features=100, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
